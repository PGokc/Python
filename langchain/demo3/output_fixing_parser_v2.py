from langchain_core.output_parsers import PydanticOutputParser
from langchain_core.runnables import RunnableLambda
from langchain_openai import ChatOpenAI
import os
from langchain_core.prompts import PromptTemplate
from langchain_core.exceptions import OutputParserException
from pydantic import BaseModel, Field


# --------------------------
# 1. å®šä¹‰ Pydantic ç»“æ„åŒ–æ¨¡å‹ï¼ˆä¸å˜ï¼‰
# --------------------------
class FlowerCopywriting(BaseModel):
    description: str = Field(
        description="é²œèŠ±çš„æè¿°æ–‡æ¡ˆï¼Œ15-30å­—ï¼Œçªå‡ºåœºæ™¯æ„Ÿå’Œå¸å¼•åŠ›",
        min_length=15,
        max_length=30
    )
    reason: str = Field(
        description="æ–‡æ¡ˆè®¾è®¡ç†ç”±ï¼Œç»“åˆä»·æ ¼å’Œå¯“æ„ï¼Œ15-25å­—",
        min_length=15,
        max_length=25
    )

# 1. åŸºç¡€ç»„ä»¶åˆå§‹åŒ–ï¼ˆå’Œ Pydantic è§£æå™¨ä¸€è‡´ï¼‰
output_parser = PydanticOutputParser(pydantic_object=FlowerCopywriting)
api_key = os.getenv("GPTSAPI_API_KEY")
base_url = 'https://api.gptsapi.net/v1'
try:
    llm = ChatOpenAI(
        api_key=api_key,
        base_url=base_url,
        model="gpt-3.5-turbo",
        temperature=0.7,
        timeout=15
    )
except Exception as e:
    raise RuntimeError(f"æ¨¡å‹åˆå§‹åŒ–å¤±è´¥ï¼š{str(e)}") from e

# 2. ä¸»ç”Ÿæˆæç¤ºè¯ï¼ˆå’ŒåŸºç¡€è§£æå™¨ä¸€è‡´ï¼‰
main_prompt = PromptTemplate(
    template="""
    ä¸º {price} å…ƒçš„ {flower} åˆ›ä½œæ–‡æ¡ˆå’Œç†ç”±ï¼Œä¸¥æ ¼éµå®ˆï¼š
    1. ä»…è¿”å› JSONï¼Œæ— é¢å¤–æ–‡å­—/æ¢è¡Œï¼›
    2. åŒ…å«å­—æ®µï¼šdescriptionï¼ˆ15-30å­—ï¼‰ã€reasonï¼ˆ15-25å­—ï¼‰ï¼›
    """,
    input_variables=["flower", "price"],
)

# 3. ä¿®å¤æç¤ºè¯ï¼ˆæ ¸å¿ƒï¼šå‘Šè¯‰ LLM å¦‚ä½•ä¿®å¤é”™è¯¯ï¼‰
fix_prompt = PromptTemplate(
    template="""
    ä½ éœ€è¦ä¿®å¤ä»¥ä¸‹é”™è¯¯çš„è¾“å‡ºï¼Œä½¿å…¶ç¬¦åˆè¦æ±‚ï¼š
    1. è¾“å‡ºæ ¼å¼ï¼šä»…è¿”å› JSONï¼ŒåŒ…å« descriptionï¼ˆ15-30å­—ï¼‰ã€reasonï¼ˆ15-25å­—ï¼‰ï¼›
    2. é”™è¯¯è¾“å‡ºï¼š{bad_output}
    3. é”™è¯¯åŸå› ï¼š{error_msg}
    æ³¨æ„ï¼šåªè¿”å›ä¿®å¤åçš„ JSONï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–å†…å®¹ï¼
    """,
    input_variables=["bad_output", "error_msg"],
)


# 4. è‡ªå®šä¹‰ä¿®å¤é€»è¾‘ï¼ˆRunnableLambda åµŒå…¥å‡½æ•°ï¼‰
def parse_or_fix(input_data):
    """è§£æå¤±è´¥åˆ™è‡ªåŠ¨ä¿®å¤"""
    bad_output = input_data["model_output"]  # æ¨¡å‹åŸå§‹è¾“å‡º
    try:
        # ç¬¬ä¸€æ¬¡å°è¯•è§£æ
        return output_parser.parse(bad_output)
    except OutputParserException as e:
        error_msg = str(e)
        print(f"âŒ è§£æå¤±è´¥ï¼š{error_msg}ï¼Œæ­£åœ¨è‡ªåŠ¨ä¿®å¤...")

        # è°ƒç”¨ LLM ä¿®å¤é”™è¯¯è¾“å‡º
        fixed_output = (fix_prompt | llm).invoke({
            "bad_output": bad_output,
            "error_msg": error_msg
        }).content

        print(f"âœ… ä¿®å¤åè¾“å‡ºï¼š{fixed_output}")
        # ä¿®å¤åé‡æ–°è§£æ
        return output_parser.parse(fixed_output)


# 5. æ„å»ºå®Œæ•´é“¾ï¼ˆç”Ÿæˆ â†’ ä¿®å¤ â†’ è§£æï¼‰
chain = (
        main_prompt
        | llm
        | RunnableLambda(lambda x: {"model_output": x.content})  # æå–æ¨¡å‹è¾“å‡º
        | RunnableLambda(parse_or_fix)  # è§£æ+è‡ªåŠ¨ä¿®å¤
)

# 6. è¿è¡Œæµ‹è¯•
if __name__ == "__main__":
    try:
        result = chain.invoke({"flower": "ç™¾åˆ", "price": "30"})
        print("\nğŸ‰ è‡ªåŠ¨ä¿®å¤è§£æå™¨æˆåŠŸï¼š")
        print(f"æ–‡æ¡ˆï¼š{result.description}")
        print(f"ç†ç”±ï¼š{result.reason}")
    except Exception as e:
        print(f"\nâŒ ä¿®å¤å¤±è´¥ï¼š{str(e)[:200]}")