import os
from typing import List
os.environ["TOKENIZERS_PARALLELISM"] = "false"

# -------------------------- 1. ä¾èµ–å¯¼å…¥ï¼ˆç¡®ä¿å·²å®‰è£…æ‰€æœ‰ä¾èµ–ï¼‰--------------------------
from langchain_community.document_loaders import PyPDFLoader, TextLoader, DirectoryLoader, Docx2txtLoader, \
    UnstructuredPDFLoader, UnstructuredFileLoader
from langchain_classic.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import SentenceTransformerEmbeddings
from langchain_chroma import Chroma
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_core.documents import Document


# -------------------------- 2. å…¨å±€é…ç½®ï¼ˆéœ€æ‰‹åŠ¨ä¿®æ”¹çš„éƒ¨åˆ†ï¼‰--------------------------
class Config:
    # çŸ¥è¯†åº“é…ç½®ï¼šæ–‡æ¡£å­˜æ”¾ç›®å½•ï¼ˆæ”¯æŒ PDF/TXT æ–‡ä»¶ï¼‰
    DOCS_DIR = "./docs"  # è¯·ç¡®ä¿è¯¥æ–‡ä»¶å¤¹å­˜åœ¨ï¼Œæ”¾å…¥ä½ çš„æ–‡æ¡£ï¼ˆå¦‚ PDF/TXTï¼‰
    # å‘é‡æ•°æ®åº“é…ç½®
    VECTOR_DB_DIR = "./chroma_rag_db"  # å‘é‡æ•°æ®æŒä¹…åŒ–è·¯å¾„ï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
    EMBEDDING_MODEL = "all-MiniLM-L6-v2"  # è½»é‡å¼€æºåµŒå…¥æ¨¡å‹ï¼ˆæ— éœ€ API Keyï¼‰
    # å¤§æ¨¡å‹é…ç½®
    OPENAI_API_KEY = os.getenv("GPTSAPI_API_KEY")  # æ›¿æ¢ä¸ºä½ çš„ API Keyï¼ˆæ”¯æŒ gptsapi å…¼å®¹æ¥å£ï¼‰
    OPENAI_BASE_URL = "https://api.gptsapi.net/v1"
    LLM_MODEL = "gpt-3.5-turbo"  # å¯é€‰ï¼šgpt-4ã€gpt-3.5-turbo-16k
    # RAG æµç¨‹é…ç½®
    CHUNK_SIZE = 500  # æ–‡æ¡£åˆ†å‰²ç‰‡æ®µé•¿åº¦ï¼ˆå­—ï¼‰
    CHUNK_OVERLAP = 50  # ç‰‡æ®µé‡å é•¿åº¦ï¼ˆé¿å…è¯­ä¹‰æ–­è£‚ï¼‰
    RETRIEVE_TOP_K = 3  # æ£€ç´¢æ—¶å¬å›çš„ç›¸å…³ç‰‡æ®µæ•°é‡ï¼ˆ3-5 ä¸ºå®œï¼‰
    TEMPERATURE = 0.1  # å¤§æ¨¡å‹æ¸©åº¦ï¼ˆ0.1-0.3 ç¡®ä¿ç­”æ¡ˆå‡†ç¡®ï¼‰


# åˆå§‹åŒ–é…ç½®å®ä¾‹
config = Config()


# -------------------------- 3. å·¥å…·å‡½æ•°ï¼šæ–‡æ¡£åŠ è½½ä¸å¤„ç†--------------------------
def load_documents(docs_dir: str) -> List[Document]:
    """
    åŠ è½½æŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰ PDF/TXT æ–‡æ¡£
    :param docs_dir: æ–‡æ¡£å­˜æ”¾ç›®å½•
    :return: åŠ è½½åçš„åŸå§‹æ–‡æ¡£åˆ—è¡¨
    """
    if not os.path.exists(docs_dir):
        os.makedirs(docs_dir)
        print(f"âš ï¸  æ–‡æ¡£ç›®å½• {docs_dir} ä¸å­˜åœ¨ï¼Œå·²è‡ªåŠ¨åˆ›å»ºï¼Œè¯·æ”¾å…¥ PDF/DOC/TXT æ–‡æ¡£åé‡æ–°è¿è¡Œ")
        exit(1)

    # å®šä¹‰åŠ è½½å™¨ï¼šæ”¯æŒ PDF å’Œ TXT æ–‡ä»¶
    loaders = [
        DirectoryLoader(
            docs_dir,
            glob="*.pdf",
            loader_cls=PyPDFLoader,
            show_progress=True,
        ),
        DirectoryLoader(
            docs_dir,
            glob="*.docx",
            loader_cls=UnstructuredFileLoader,
            show_progress=True,
        ),
        DirectoryLoader(
            docs_dir,
            glob="*.txt",
            loader_cls=TextLoader,
            show_progress=True,
            loader_kwargs={"encoding": "utf-8"}
        ),
    ]

    # åŠ è½½æ‰€æœ‰æ–‡æ¡£
    documents = []
    for loader in loaders:
        try:
            docs = loader.load()
            documents.extend(docs)
        except Exception as e:
            print(f"âš ï¸  åŠ è½½ {loader.glob} æ–‡æ¡£æ—¶å‡ºé”™ï¼š{str(e)}")

    if not documents:
        print(f"âš ï¸  æœªåœ¨ {docs_dir} ç›®å½•ä¸‹æ‰¾åˆ° PDF/TXT æ–‡æ¡£ï¼Œè¯·æ”¾å…¥æ–‡æ¡£åé‡æ–°è¿è¡Œ")
        exit(1)

    print(f"âœ… æˆåŠŸåŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£")
    return documents


def split_documents(documents: List[Document]) -> List[Document]:
    """
    å°†é•¿æ–‡æ¡£åˆ†å‰²ä¸ºçŸ­ç‰‡æ®µï¼ˆé€‚é…æ¨¡å‹ä¸Šä¸‹æ–‡çª—å£ï¼‰
    """
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=config.CHUNK_SIZE,
        chunk_overlap=config.CHUNK_OVERLAP,
        length_function=len,  # æŒ‰å­—ç¬¦æ•°è®¡ç®—é•¿åº¦
        separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼›", "ï¼Œ", " ", ""]  # ä¸­æ–‡ä¼˜å…ˆåˆ†å‰²ç¬¦
    )
    chunks = text_splitter.split_documents(documents)
    print(f"âœ… æ–‡æ¡£åˆ†å‰²å®Œæˆï¼Œå…±å¾—åˆ° {len(chunks)} ä¸ªæ–‡æœ¬ç‰‡æ®µ")
    return chunks


# -------------------------- 4. åˆå§‹åŒ–å‘é‡æ•°æ®åº“ä¸æ£€ç´¢å™¨--------------------------
def init_vector_db(chunks: List[Document]) -> Chroma:
    """
    åˆå§‹åŒ–å‘é‡æ•°æ®åº“ï¼Œå°†æ–‡æœ¬ç‰‡æ®µå‘é‡åŒ–åå­˜å…¥
    """
    # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹ï¼ˆå¼€æºã€è½»é‡ã€æ— éœ€ API Keyï¼‰
    embedding = SentenceTransformerEmbeddings(model_name=config.EMBEDDING_MODEL)

    # æ£€æŸ¥å‘é‡æ•°æ®åº“æ˜¯å¦å·²å­˜åœ¨
    if os.path.exists(config.VECTOR_DB_DIR):
        # åŠ è½½å·²æœ‰æ•°æ®åº“
        db = Chroma(
            persist_directory=config.VECTOR_DB_DIR,
            embedding_function=embedding
        )
        print(f"âœ… æˆåŠŸåŠ è½½å·²å­˜åœ¨çš„å‘é‡æ•°æ®åº“ï¼ˆ{config.VECTOR_DB_DIR}ï¼‰")
    else:
        # æ–°å»ºæ•°æ®åº“å¹¶æ’å…¥æ–‡æœ¬ç‰‡æ®µ
        db = Chroma.from_documents(
            documents=chunks,
            embedding=embedding,
            persist_directory=config.VECTOR_DB_DIR
        )
        print(f"âœ… æ–°å»ºå‘é‡æ•°æ®åº“å®Œæˆï¼Œæ•°æ®å·²ä¿å­˜è‡³ {config.VECTOR_DB_DIR}")

    return db


def build_retriever(db: Chroma) -> RunnablePassthrough:
    """
    æ„å»ºæ£€ç´¢å™¨ï¼ˆä»å‘é‡æ•°æ®åº“ä¸­å¬å›ç›¸å…³ç‰‡æ®µï¼‰
    """
    retriever = db.as_retriever(
        search_kwargs={"k": config.RETRIEVE_TOP_K},
        search_type="similarity"  # åŸºç¡€ç›¸ä¼¼æ€§æ£€ç´¢ï¼ˆé€‚åˆå…¥é—¨ï¼‰
    )
    return retriever


# -------------------------- 5. æ„å»º RAG æµæ°´çº¿ï¼ˆæ£€ç´¢+ç”Ÿæˆï¼‰--------------------------
def build_rag_chain(retriever: RunnablePassthrough) -> RunnablePassthrough:
    """
    æ„å»ºå®Œæ•´ RAG æµæ°´çº¿ï¼šç”¨æˆ·é—®é¢˜â†’æ£€ç´¢ç›¸å…³æ–‡æ¡£â†’ç”Ÿæˆç­”æ¡ˆ
    """
    # åˆå§‹åŒ–å¤§æ¨¡å‹
    llm = ChatOpenAI(
        api_key=config.OPENAI_API_KEY,
        base_url=config.OPENAI_BASE_URL,
        model=config.LLM_MODEL,
        temperature=config.TEMPERATURE,
        timeout=30
    )

    # æ„å»º Promptï¼ˆæ ¸å¿ƒï¼šå¼•å¯¼æ¨¡å‹åŸºäºæ£€ç´¢æ–‡æ¡£ç”Ÿæˆç­”æ¡ˆï¼‰
    prompt = ChatPromptTemplate.from_messages([
        ("system", """
        ä½ æ˜¯ä¸€ä¸ªåŸºäºå‚è€ƒæ–‡æ¡£çš„æ™ºèƒ½é—®ç­”åŠ©æ‰‹ï¼Œä¸¥æ ¼éµå¾ªä»¥ä¸‹è§„åˆ™ï¼š
        1. æ‰€æœ‰ç­”æ¡ˆå¿…é¡»å®Œå…¨åŸºäºæä¾›çš„å‚è€ƒæ–‡æ¡£ç‰‡æ®µï¼Œä¸æ·»åŠ ä»»ä½•å¤–éƒ¨çŸ¥è¯†ï¼›
        2. è‹¥å‚è€ƒæ–‡æ¡£ä¸­æ²¡æœ‰ä¸ç”¨æˆ·é—®é¢˜ç›¸å…³çš„ä¿¡æ¯ï¼Œç›´æ¥å›å¤ã€ŒæœªæŸ¥è¯¢åˆ°ç›¸å…³ä¿¡æ¯ã€ï¼Œç¦æ­¢ç¼–é€ ç­”æ¡ˆï¼›
        3. ç­”æ¡ˆéœ€ç®€æ´ã€æœ‰æ¡ç†ï¼Œä¼˜å…ˆä½¿ç”¨åˆ†ç‚¹å½¢å¼å‘ˆç°å…³é”®ä¿¡æ¯ï¼›
        4. æ— éœ€æåŠã€Œæ ¹æ®å‚è€ƒæ–‡æ¡£ã€ç­‰è¡¨è¿°ï¼Œç›´æ¥ç»™å‡ºç­”æ¡ˆå³å¯ã€‚
        """),
        ("user", "å‚è€ƒæ–‡æ¡£ï¼š\n{context}\n\nç”¨æˆ·é—®é¢˜ï¼š{question}")
    ])

    # æ„å»ºæµæ°´çº¿ï¼šæ£€ç´¢â†’æ‹¼æ¥ä¸Šä¸‹æ–‡â†’Promptâ†’å¤§æ¨¡å‹â†’è¾“å‡ºè§£æ
    rag_chain = (
            {
                "context": retriever | (lambda docs: "\n\n".join([d.page_content for d in docs])),
                "question": RunnablePassthrough()  # ä¼ é€’ç”¨æˆ·åŸå§‹é—®é¢˜
            }
            | prompt
            | llm
            | StrOutputParser()  # è§£æå¤§æ¨¡å‹è¾“å‡ºä¸ºå­—ç¬¦ä¸²
    )

    return rag_chain


# -------------------------- 6. æµ‹è¯•å‡½æ•°ï¼šäº¤äº’å¼é—®ç­”--------------------------
def interactive_qa(rag_chain: RunnablePassthrough):
    """
    äº¤äº’å¼é—®ç­”ï¼šæŒç»­æ¥æ”¶ç”¨æˆ·é—®é¢˜ï¼Œè¿”å› RAG ç”Ÿæˆçš„ç­”æ¡ˆ
    """
    print("\n" + "=" * 60)
    print("ğŸ¯ RAG æ™ºèƒ½é—®ç­”ç³»ç»Ÿå·²å¯åŠ¨ï¼ˆè¾“å…¥ 'é€€å‡º' ç»“æŸå¯¹è¯ï¼‰")
    print("ğŸ’¡ æç¤ºï¼šå¯è¯¢é—®æ–‡æ¡£ä¸­çš„ç›¸å…³é—®é¢˜ï¼ˆå¦‚äº§å“åŠŸèƒ½ã€æ”¿ç­–æ¡æ¬¾ç­‰ï¼‰")
    print("=" * 60 + "\n")

    while True:
        user_input = input("ç”¨æˆ·ï¼š")
        if user_input.strip() in ["é€€å‡º", "quit", "exit"]:
            print("åŠ©æ‰‹ï¼šå†è§ï¼æœ‰ä»»ä½•é—®é¢˜éšæ—¶å›æ¥~")
            break
        if not user_input.strip():
            print("åŠ©æ‰‹ï¼šè¯·è¾“å…¥å…·ä½“é—®é¢˜~")
            continue

        try:
            # æ‰§è¡Œ RAG æµæ°´çº¿ï¼Œç”Ÿæˆç­”æ¡ˆ
            answer = rag_chain.invoke(user_input)
            print(f"åŠ©æ‰‹ï¼š{answer}\n")
        except Exception as e:
            print(f"âš ï¸  ç”Ÿæˆç­”æ¡ˆæ—¶å‡ºé”™ï¼š{str(e)}\n")


# -------------------------- 7. ä¸»å‡½æ•°ï¼šä¸²è”å…¨æµç¨‹--------------------------
def main():
    try:
        # æ­¥éª¤1ï¼šåŠ è½½æ–‡æ¡£
        documents = load_documents(config.DOCS_DIR)

        # æ­¥éª¤2ï¼šåˆ†å‰²æ–‡æ¡£ä¸ºçŸ­ç‰‡æ®µ
        chunks = split_documents(documents)

        # æ­¥éª¤3ï¼šåˆå§‹åŒ–å‘é‡æ•°æ®åº“
        db = init_vector_db(chunks)

        # æ­¥éª¤4ï¼šæ„å»ºæ£€ç´¢å™¨
        retriever = build_retriever(db)

        # æ­¥éª¤5ï¼šæ„å»º RAG æµæ°´çº¿
        rag_chain = build_rag_chain(retriever)

        # æ­¥éª¤6ï¼šå¯åŠ¨äº¤äº’å¼é—®ç­”
        interactive_qa(rag_chain)

    except Exception as e:
        print(f"âŒ ç³»ç»Ÿè¿è¡Œå‡ºé”™ï¼š{str(e)}")


if __name__ == "__main__":
    main()