import os
import time
from typing import Dict, Any

from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.callbacks import BaseCallbackHandler, StdOutCallbackHandler


# 1. è‡ªå®šä¹‰å›è°ƒç±»ï¼ˆç»§æ‰¿ BaseCallbackHandlerï¼‰
class PerformanceMonitorCallback(BaseCallbackHandler):
    # LLM å¼€å§‹è°ƒç”¨æ—¶è§¦å‘
    def __init__(self):
        self.start_time = None

    def on_llm_start(
        self, serialized: Dict[str, Any], prompts: list[str], **kwargs
    ) -> None:
        self.start_time = time.time()
        print(f"\nğŸ“Š LLM å¼€å§‹è°ƒç”¨ï¼ŒPromptï¼š{prompts[0]}")

    # LLM è°ƒç”¨æˆåŠŸç»“æŸæ—¶è§¦å‘
    def on_llm_end(self, response: Any, **kwargs) -> None:
        elapsed_time = time.time() - self.start_time
        print(f"ğŸ“Š LLM è°ƒç”¨å®Œæˆï¼Œè€—æ—¶ï¼š{elapsed_time:.2f} ç§’")

    # LLM è°ƒç”¨å‡ºé”™æ—¶è§¦å‘ï¼ˆå¯é€‰ï¼‰
    def on_llm_error(self, error: Exception, **kwargs) -> None:
        print(f"âŒ LLM è°ƒç”¨å¤±è´¥ï¼š{str(error)}")

# 2. æ³¨å†Œè‡ªå®šä¹‰å›è°ƒï¼ˆå¯åŒæ—¶æ³¨å†Œå¤šä¸ªï¼‰
llm_with_monitor = ChatOpenAI(
    api_key=os.getenv("GPTSAPI_API_KEY"),
    base_url="https://api.gptsapi.net/v1",
    model="claude-3-sonnet-20240229",
    callbacks=[
        StdOutCallbackHandler(),  # å†…ç½®æ—¥å¿—å›è°ƒ
        PerformanceMonitorCallback()  # è‡ªå®šä¹‰æ€§èƒ½å›è°ƒ
    ]
)

# é“¾çº§åˆ«å›è°ƒ
class ChainMonitorCallback(BaseCallbackHandler):
    # é“¾å¼€å§‹æ‰§è¡Œæ—¶è§¦å‘
    def __init__(self):
        self.chain_start_time = None

    def on_chain_start(
        self, serialized: Dict[str, Any], inputs: Dict[str, Any], **kwargs
    ) -> None:
        self.chain_start_time = time.time()
        print(f"\nğŸ”— é“¾å¼€å§‹æ‰§è¡Œï¼Œè¾“å…¥ï¼š{inputs}")

    # é“¾æ‰§è¡ŒæˆåŠŸç»“æŸæ—¶è§¦å‘
    def on_chain_end(self, outputs: Any, **kwargs) -> None:
        chain_elapsed = time.time() - self.chain_start_time
        print(f"ğŸ”— é“¾æ‰§è¡Œå®Œæˆï¼Œè€—æ—¶ï¼š{chain_elapsed:.2f} ç§’ï¼Œè¾“å‡ºé•¿åº¦ï¼š{len(outputs.content)} å­—")

# ç»„è£…é“¾æ—¶æ³¨å†Œå›è°ƒï¼ˆé“¾å±‚çº§ï¼Œè¦†ç›– LLM å±‚çº§å›è°ƒï¼‰
prompt = ChatPromptTemplate.from_messages([("human", "ç”¨ 2 å¥è¯ä»‹ç» LangChain æœ€æ–°ç‰ˆ")])
chain_with_chain_callback = prompt | llm_with_monitor
chain_with_chain_callback = chain_with_chain_callback.with_config(
    callbacks=[ChainMonitorCallback()]  # é“¾çº§å›è°ƒ
)

print("\n=== è‡ªå®šä¹‰ ChainMonitorCallback æ¼”ç¤º ===")
chain_with_chain_callback.invoke({"input": ""})